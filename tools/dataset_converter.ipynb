{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file D:\\recsys\\datasets\\MovieLens\\ml-1m-gte.csv\n",
      "UR: 226310 EXP: 19437248 User: 6014 Item: 3232 CR: 98.84%\n",
      "Reading file D:\\recsys\\datasets\\MovieLens\\ml-100k-gte.csv\n",
      "UR: 21201 EXP: 1087616 User: 928 Item: 1172 CR: 98.05%\n",
      "Reading file D:\\recsys\\datasets\\palco\\music_playlist.csv\n",
      "UR: 111927 EXP: 271407864 User: 10392 Item: 26117 CR: 99.96%\n",
      "Reading file D:\\recsys\\datasets\\palco\\music_listen.csv\n",
      "UR: 784360 EXP: 1023943619 User: 25463 Item: 40213 CR: 99.92%\n",
      "Reading file D:\\recsys\\datasets\\CiaoDVD\\ciaodvd-gte.csv\n",
      "UR: 32530 EXP: 105705108 User: 12508 Item: 8451 CR: 99.97%\n",
      "Reading file D:\\recsys\\datasets\\EachMovie\\eachmovie-gte.csv\n",
      "UR: 511614 EXP: 84075740 User: 54068 Item: 1555 CR: 99.39%\n",
      "Reading file D:\\recsys\\datasets\\MovieTweetings\\movietweetings-gte.csv\n",
      "UR: 14814 EXP: 20288368 User: 4856 Item: 4178 CR: 99.93%\n",
      "Reading file D:\\recsys\\datasets\\YELP\\yelp_dataset\\yelp-gte.csv\n",
      "UR: 2641878 EXP: 172325625530 User: 1033561 Item: 166730 CR: 100.00%\n",
      "Reading file D:\\recsys\\datasets\\LastFM\\lastfm-dataset-360K\\lastfm-dataset-1K\\last-fm.csv\n",
      "UR: 4618291 EXP: 1488655712 User: 992 Item: 1500661 CR: 99.69%\n",
      "Reading file D:\\recsys\\datasets\\Netflix\\netflix-gte.csv\n",
      "UR: 23168232 EXP: 8231502080 User: 17755 Item: 463616 CR: 99.72%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Size</th>\n",
       "      <th>Unique Rating</th>\n",
       "      <th>Users</th>\n",
       "      <th>Last User ID</th>\n",
       "      <th>Items</th>\n",
       "      <th>Last Item ID</th>\n",
       "      <th>Avg Rate</th>\n",
       "      <th>Min Rate</th>\n",
       "      <th>Max Rate</th>\n",
       "      <th>Sparsity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>movietweetings-gte.csv</td>\n",
       "      <td>14842</td>\n",
       "      <td>99.811346</td>\n",
       "      <td>4856</td>\n",
       "      <td>24899</td>\n",
       "      <td>4178</td>\n",
       "      <td>15131</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>99.926983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ml-100k-gte.csv</td>\n",
       "      <td>21201</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>928</td>\n",
       "      <td>943</td>\n",
       "      <td>1172</td>\n",
       "      <td>1656</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>98.050691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ciaodvd-gte.csv</td>\n",
       "      <td>32695</td>\n",
       "      <td>99.495336</td>\n",
       "      <td>12508</td>\n",
       "      <td>17615</td>\n",
       "      <td>8451</td>\n",
       "      <td>16119</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>306</td>\n",
       "      <td>99.969226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>music_playlist.csv</td>\n",
       "      <td>111942</td>\n",
       "      <td>99.986600</td>\n",
       "      <td>10392</td>\n",
       "      <td>88921</td>\n",
       "      <td>26117</td>\n",
       "      <td>126623</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2430</td>\n",
       "      <td>99.958761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ml-1m-gte.csv</td>\n",
       "      <td>226310</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>6014</td>\n",
       "      <td>6040</td>\n",
       "      <td>3232</td>\n",
       "      <td>3952</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>571</td>\n",
       "      <td>98.835689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eachmovie-gte.csv</td>\n",
       "      <td>511667</td>\n",
       "      <td>99.989642</td>\n",
       "      <td>54068</td>\n",
       "      <td>74424</td>\n",
       "      <td>1555</td>\n",
       "      <td>1648</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>448</td>\n",
       "      <td>99.391484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>music_listen.csv</td>\n",
       "      <td>1466893</td>\n",
       "      <td>53.470839</td>\n",
       "      <td>25463</td>\n",
       "      <td>25462</td>\n",
       "      <td>40213</td>\n",
       "      <td>40212</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>61714</td>\n",
       "      <td>99.923398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>yelp-gte.csv</td>\n",
       "      <td>2641880</td>\n",
       "      <td>99.999924</td>\n",
       "      <td>1033561</td>\n",
       "      <td>1518168</td>\n",
       "      <td>166730</td>\n",
       "      <td>188592</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>463</td>\n",
       "      <td>99.998467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>last-fm.csv</td>\n",
       "      <td>19150868</td>\n",
       "      <td>24.115309</td>\n",
       "      <td>992</td>\n",
       "      <td>1000</td>\n",
       "      <td>1500661</td>\n",
       "      <td>1500660</td>\n",
       "      <td>19305</td>\n",
       "      <td>2</td>\n",
       "      <td>183103</td>\n",
       "      <td>99.689768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>netflix-gte.csv</td>\n",
       "      <td>23168232</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>17755</td>\n",
       "      <td>17770</td>\n",
       "      <td>463616</td>\n",
       "      <td>480188</td>\n",
       "      <td>1304</td>\n",
       "      <td>1</td>\n",
       "      <td>96535</td>\n",
       "      <td>99.718542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Filename      Size  Unique Rating    Users  Last User ID  \\\n",
       "6  movietweetings-gte.csv     14842      99.811346     4856         24899   \n",
       "1         ml-100k-gte.csv     21201     100.000000      928           943   \n",
       "4         ciaodvd-gte.csv     32695      99.495336    12508         17615   \n",
       "2      music_playlist.csv    111942      99.986600    10392         88921   \n",
       "0           ml-1m-gte.csv    226310     100.000000     6014          6040   \n",
       "5       eachmovie-gte.csv    511667      99.989642    54068         74424   \n",
       "3        music_listen.csv   1466893      53.470839    25463         25462   \n",
       "7            yelp-gte.csv   2641880      99.999924  1033561       1518168   \n",
       "8             last-fm.csv  19150868      24.115309      992          1000   \n",
       "9         netflix-gte.csv  23168232     100.000000    17755         17770   \n",
       "\n",
       "     Items  Last Item ID  Avg Rate  Min Rate  Max Rate   Sparsity  \n",
       "6     4178         15131         3         1        83  99.926983  \n",
       "1     1172          1656        22         1       172  98.050691  \n",
       "4     8451         16119         2         1       306  99.969226  \n",
       "2    26117        126623        10         1      2430  99.958761  \n",
       "0     3232          3952        37         1       571  98.835689  \n",
       "5     1555          1648         9         1       448  99.391484  \n",
       "3    40213         40212        57         1     61714  99.923398  \n",
       "7   166730        188592         2         1       463  99.998467  \n",
       "8  1500661       1500660     19305         2    183103  99.689768  \n",
       "9   463616        480188      1304         1     96535  99.718542  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract(paths):\n",
    "    information_table = \"Filename\\t\\tUsers\\tItems\\tRatings\\tSparsity\\n\"\n",
    "    filenames = []\n",
    "    n_instances = []\n",
    "    unique_ratings = []\n",
    "    n_users = []\n",
    "    l_users = []\n",
    "    n_items = []\n",
    "    l_items = []\n",
    "    sparsities = []\n",
    "    min_ratings = []\n",
    "    max_ratings = []\n",
    "    avg_ratings = []\n",
    "    time_periods = []\n",
    "\n",
    "    \n",
    "    for path in paths:\n",
    "        users = []\n",
    "        items = []\n",
    "        ratings = []\n",
    "        timestamps = []\n",
    "\n",
    "        print('Reading file {}'.format(path))\n",
    "        with open(path, 'r') as f:\n",
    "            for index, line in enumerate(f):\n",
    "                line = line.replace(\"\\n\", \"\")\n",
    "                if line == \"\":\n",
    "                    continue\n",
    "                user, item, rating, timestamp = line.split(\",\")\n",
    "                users.append(int(user))\n",
    "                items.append(int(item))\n",
    "                ratings.append(int(rating))\n",
    "                timestamps.append(int(timestamp))\n",
    "        df = pd.DataFrame({\"User\": users, \"Item\": items, \"Rating\": ratings, \"Timestamp\": timestamps})\n",
    "        \n",
    "        filename = path.split(\"\\\\\")[-1]\n",
    "        filenames.append(filename)\n",
    "        \n",
    "        n_instances.append(df.shape[0])\n",
    "        \n",
    "        users = df.groupby(\"User\").count().index.values\n",
    "        users.sort()\n",
    "        n_user = users.shape[0]\n",
    "        \n",
    "        l_users.append(users[-1])\n",
    "        n_users.append(n_user)\n",
    "        \n",
    "        items = df.groupby(\"Item\").count().index.values\n",
    "        items.sort()\n",
    "        n_item = items.shape[0]\n",
    "        \n",
    "        l_items.append(items[-1])\n",
    "        n_items.append(n_item)\n",
    "        \n",
    "        min_ratings.append(df.groupby(\"User\").count()[\"Item\"].min())\n",
    "        max_ratings.append(df.groupby(\"User\").count()[\"Item\"].max())\n",
    "        avg_ratings.append(int(df.groupby(\"User\").count()[\"Item\"].mean()))\n",
    "        \n",
    "        \n",
    "        unique_rating = df.groupby([\"User\", \"Item\"]).count().shape[0]\n",
    "        print(\"UR: {} EXP: {} User: {} Item: {} CR: {:.2f}%\".format(unique_rating, n_user*n_item, n_user, n_item, (1 - unique_rating/(n_user*n_item))*100))\n",
    "        sparsity = (1 - unique_rating/(n_user*n_item)) * 100\n",
    "        sparsities.append(sparsity)\n",
    "        unique_ratings.append(unique_rating/df.shape[0]*100)\n",
    "    return pd.DataFrame({\"Filename\":filenames, \"Size\": n_instances, \"Unique Rating\": unique_ratings, \"Users\":n_users, \"Last User ID\": l_users, \"Items\":n_items, \"Last Item ID\": l_items, \"Avg Rate\":avg_ratings, \"Min Rate\":min_ratings, \"Max Rate\":max_ratings, \"Sparsity\":sparsities}).sort_values(by=[\"Size\"])     \n",
    "    \n",
    "paths = [\n",
    "    \"D:\\\\recsys\\\\datasets\\\\MovieLens\\\\ml-1m-gte.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\MovieLens\\\\ml-100k-gte.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\palco\\\\music_playlist.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\palco\\\\music_listen.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\CiaoDVD\\\\ciaodvd-gte.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\EachMovie\\\\eachmovie-gte.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\MovieTweetings\\\\movietweetings-gte.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\YELP\\\\yelp_dataset\\\\yelp-gte.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\LastFM\\\\lastfm-dataset-360K\\\\lastfm-dataset-1K\\\\last-fm.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\Netflix\\\\netflix-gte.csv\"\n",
    "]\n",
    "\n",
    "extract(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file D:\\recsys\\datasets\\MovieLens\\ml-1m-gte.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\MovieLens\\ml-100k-gte.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\palco\\music_playlist.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\palco\\music_listen.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\CiaoDVD\\ciaodvd-gte.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\EachMovie\\eachmovie-gte.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\MovieTweetings\\movietweetings-gte.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\YELP\\yelp_dataset\\yelp-gte.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\LastFM\\lastfm-dataset-360K\\lastfm-dataset-1K\\last-fm.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Netflix\\netflix-gte.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "# Since the framework use the user index to access the matrix, the best way to do it is maintaining close to zero, without users/items gaps\n",
    "# This function remap every user and item to be as close as possible to zero. \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def optimizer(paths):\n",
    "    optimize_path = \"D:\\\\recsys\\\\datasets\\\\optimized\\\\{}\"\n",
    "    for path in paths:\n",
    "        \n",
    "        users = []\n",
    "        items = []\n",
    "        ratings = []\n",
    "        timestamps = []\n",
    "\n",
    "        print('Reading file {}'.format(path))\n",
    "        with open(path, 'r') as f:\n",
    "            for index, line in enumerate(f):\n",
    "                line = line.replace(\"\\n\", \"\")\n",
    "                if line == \"\":\n",
    "                    continue\n",
    "                user, item, rating, timestamp = line.split(\",\")\n",
    "                users.append(int(user))\n",
    "                items.append(int(item))\n",
    "                ratings.append(int(rating))\n",
    "                timestamps.append(int(timestamp))\n",
    "        df = pd.DataFrame({\"User\": users, \"Item\": items, \"Rating\": ratings, \"Timestamp\": timestamps})\n",
    "        \n",
    "        filename = path.split(\"\\\\\")[-1]\n",
    "        \n",
    "        print(\"Grouping users and items ... \", end=\"\")\n",
    "        items = df.groupby(\"Item\").count().index.values\n",
    "        users = df.groupby(\"User\").count().index.values\n",
    "        item_dict = {}\n",
    "        user_dict = {}\n",
    "        print(\"OK\")\n",
    "\n",
    "\n",
    "        print(\"Adding to a dictionary ... \" , end=\"\")\n",
    "        for index, item in enumerate(items):\n",
    "            item_dict[item] = index\n",
    "        for index, user in enumerate(users):\n",
    "            user_dict[user] = index\n",
    "        print(\"OK\")     \n",
    "        \n",
    "        print('Writing csv file ... ', end=\"\")\n",
    "        with open(optimize_path.format(filename), 'w+') as f:\n",
    "            for index, row in df.iterrows():\n",
    "                f.write(\"{},{},{},{}\\n\".format(user_dict[row['User']], item_dict[row['Item']], row['Rating'], row['Timestamp']))\n",
    "        print(\"OK\")\n",
    "        \n",
    "paths = [\n",
    "    \"D:\\\\recsys\\\\datasets\\\\MovieLens\\\\ml-1m-gte.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\MovieLens\\\\ml-100k-gte.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\palco\\\\music_playlist.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\palco\\\\music_listen.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\CiaoDVD\\\\ciaodvd-gte.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\EachMovie\\\\eachmovie-gte.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\MovieTweetings\\\\movietweetings-gte.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\YELP\\\\yelp_dataset\\\\yelp-gte.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\LastFM\\\\lastfm-dataset-360K\\\\lastfm-dataset-1K\\\\last-fm.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\Netflix\\\\netflix-gte.csv\"\n",
    "]\n",
    "\n",
    "optimizer(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_sampling(data, k):\n",
    "    size = data.shape[0]\n",
    "\n",
    "    st = data.loc[[e for e in range(size) if e % k == 0]]\n",
    "    \n",
    "    users = st.groupby(\"User\").count().sort_values(by=[\"Timestamp\"], ascending = False)[\"Item\"]\n",
    "    user_size = users.shape[0]\n",
    "    selected_users = users.iloc[[e for e in range(user_size) if e % k == 0  ]].index.values\n",
    "\n",
    "    items = st.groupby(\"Item\").count().sort_values(by=[\"Timestamp\"], ascending = False)[\"User\"]\n",
    "    item_size = items.shape[0]\n",
    "    selected_items = items.iloc[[e for e in range(item_size) if e % k == 0  ]].index.values\n",
    "    \n",
    "    index_list = []\n",
    "    for index, row in data.iterrows():\n",
    "        if row[\"User\"] in selected_users and row[\"Item\"] in selected_items:\n",
    "            index_list.append(index)\n",
    "    return data.iloc[index_list].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_k_samples(path, k_values):\n",
    "    base = path.split(\".\")[0]\n",
    "    out = base + \"-K{}.csv\" \n",
    "    users = []\n",
    "    items = []\n",
    "    ratings = []\n",
    "    timestamps = []\n",
    "    print('Reading file {} .. '.format(path), end=\"\")\n",
    "    with open(path, 'r') as f:\n",
    "        for index, line in enumerate(f):\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            if line == \"\":\n",
    "                continue\n",
    "            user, item, rating, timestamp = line.split(\",\")\n",
    "            users.append(int(user))\n",
    "            items.append(int(item))\n",
    "            ratings.append(int(rating))\n",
    "            timestamps.append(int(timestamp))\n",
    "    df = pd.DataFrame({\"User\": users, \"Item\": items, \"Rating\": ratings, \"Timestamp\": timestamps})\n",
    "    print(\"OK\")\n",
    "    \n",
    "    print(\"Starting K-sampling ..\")\n",
    "    for k_value in k_values:\n",
    "        print(\"K{} data sampling ..\".format(k_value), end=\"\")\n",
    "        st = k_sampling(df, k_value)\n",
    "        print(\"OK\")\n",
    "        print(\"Writing file .. \", end=\"\")\n",
    "        with open(out.format(k_value), 'w+') as f:\n",
    "            for index, row in st.iterrows():\n",
    "                f.write(\"{},{},{},{}\\n\".format(row['User'], row['Item'], row['Rating'], row['Timestamp']))\n",
    "        print(\"OK\")\n",
    "        del st\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ciaodvd-gte-K2.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ciaodvd-gte-K3.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ciaodvd-gte-K4.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ciaodvd-gte-K5.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ciaodvd-gte-K6.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ciaodvd-gte-K7.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ciaodvd-gte-K8.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ciaodvd-gte-K9.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ciaodvd-gte-K10.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ciaodvd-gte-K11.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ciaodvd-gte-K12.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ciaodvd-gte-K13.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ciaodvd-gte-K14.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\eachmovie-gte-K2.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\eachmovie-gte-K3.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\eachmovie-gte-K4.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\eachmovie-gte-K5.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\eachmovie-gte-K6.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\eachmovie-gte-K7.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\eachmovie-gte-K8.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\eachmovie-gte-K9.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\eachmovie-gte-K10.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\eachmovie-gte-K11.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\eachmovie-gte-K12.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\eachmovie-gte-K13.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\eachmovie-gte-K14.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-1m-gte-K2.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-1m-gte-K3.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-1m-gte-K4.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-1m-gte-K5.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-1m-gte-K6.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-1m-gte-K7.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-1m-gte-K8.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-1m-gte-K9.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-1m-gte-K10.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-1m-gte-K11.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-1m-gte-K12.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-1m-gte-K13.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-1m-gte-K14.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-100k-gte-K2.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-100k-gte-K3.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-100k-gte-K4.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-100k-gte-K5.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-100k-gte-K6.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-100k-gte-K7.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-100k-gte-K8.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-100k-gte-K9.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-100k-gte-K10.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-100k-gte-K11.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-100k-gte-K12.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-100k-gte-K13.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\ml-100k-gte-K14.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\movietweetings-gte-K2.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\movietweetings-gte-K3.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\movietweetings-gte-K4.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\movietweetings-gte-K5.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\movietweetings-gte-K6.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\movietweetings-gte-K7.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\movietweetings-gte-K8.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\movietweetings-gte-K9.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\movietweetings-gte-K10.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\movietweetings-gte-K11.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\movietweetings-gte-K12.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\movietweetings-gte-K13.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\movietweetings-gte-K14.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\music-playlist-K2.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\music-playlist-K3.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\music-playlist-K4.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\music-playlist-K5.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\music-playlist-K6.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\music-playlist-K7.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\music-playlist-K8.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\music-playlist-K9.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\music-playlist-K10.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\music-playlist-K11.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\music-playlist-K12.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\music-playlist-K13.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\music-playlist-K14.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\yelp-gte-K2.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\yelp-gte-K3.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\yelp-gte-K4.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\yelp-gte-K5.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\yelp-gte-K6.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\yelp-gte-K7.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\yelp-gte-K8.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\yelp-gte-K9.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\yelp-gte-K10.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\yelp-gte-K11.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\yelp-gte-K12.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\yelp-gte-K13.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\yelp-gte-K14.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\last-fm-K2.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\last-fm-K3.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\last-fm-K4.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\last-fm-K5.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\last-fm-K6.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\last-fm-K7.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\last-fm-K8.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\last-fm-K9.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\last-fm-K10.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\last-fm-K11.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\last-fm-K12.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\last-fm-K13.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n",
      "Reading file D:\\recsys\\datasets\\Experimentation Protocol\\K_Sampling\\last-fm-K14.csv\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "data_paths = [\n",
    "    \"D:\\\\recsys\\\\datasets\\\\Experimentation Protocol\\\\K_Sampling\\\\ciaodvd-gte.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\Experimentation Protocol\\\\K_Sampling\\\\eachmovie-gte.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\Experimentation Protocol\\\\K_Sampling\\\\ml-1m-gte.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\Experimentation Protocol\\\\K_Sampling\\\\ml-100k-gte.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\Experimentation Protocol\\\\K_Sampling\\\\movietweetings-gte.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\Experimentation Protocol\\\\K_Sampling\\\\music-playlist.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\Experimentation Protocol\\\\K_Sampling\\\\yelp-gte.csv\",\n",
    "    \"D:\\\\recsys\\\\datasets\\\\Experimentation Protocol\\\\K_Sampling\\\\last-fm.csv\"\n",
    "]\n",
    "\n",
    "k_values = list(range(2, 15))\n",
    "\n",
    "# for path in data_paths:\n",
    "#     generate_k_samples(path, k_values)\n",
    "\n",
    "k_samples_path = []\n",
    "\n",
    "for path in data_paths:\n",
    "    for k_value in k_values:\n",
    "        k_samples_path.append(\"{}-K{}.csv\".format(path.split(\".\")[0], k_value))\n",
    "        \n",
    "optimizer(k_samples_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens 1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = \"D:\\\\recsys\\\\datasets\\\\MovieLens\\\\ml-1m\\\\ratings.dat\"\n",
    "output = \"D:\\\\recsys\\\\datasets\\\\MovieLens\\\\ml-1m\\\\ml-1m-K{}.csv\"\n",
    "output_positive_only = \"D:\\\\recsys\\\\datasets\\\\MovieLens\\\\ml-1m\\\\ml-1m-K{}-gte.csv\"\n",
    "\n",
    "users = []\n",
    "items = []\n",
    "ratings = []\n",
    "timestamps = []\n",
    "k_value = 2\n",
    "\n",
    "\n",
    "print('Reading file {}'.format(path))\n",
    "with open(path, 'r') as f:\n",
    "    for index, line in enumerate(f):\n",
    "        line = line.replace(\"\\n\", \"\")\n",
    "        if line == \"\":\n",
    "            continue\n",
    "        user, item, rating, timestamp = line.split(\"::\")\n",
    "        users.append(int(user))\n",
    "        items.append(int(item))\n",
    "        ratings.append(int(rating))\n",
    "        timestamps.append(int(timestamp))\n",
    "    df = pd.DataFrame({\"User\": users, \"Item\": items, \"Rating\": ratings, \"Timestamp\": timestamps})\n",
    "    \n",
    "print('Sorting by timestamp')\n",
    "df = df.sort_values(by=[\"Timestamp\"])\n",
    "\n",
    "print('K{}-Sampling'.format(k_value))\n",
    "df = k_sampling(df, k_value)\n",
    "\n",
    "print('Writing csv file')\n",
    "with open(output.format(k_value), 'w+') as f:\n",
    "    with open(output_positive_only.format(k_value), \"w+\") as f_positive:\n",
    "        for index, row in df.iterrows():\n",
    "            f.write(\"{},{},{},{}\\n\".format(row['User'], row['Item'], row['Rating'], row['Timestamp']))\n",
    "            if row['Rating'] == 5:\n",
    "                f_positive.write(\"{},{},1,{}\\n\".format(row['User'], row['Item'], row['Timestamp']))\n",
    "print(\"Complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens 100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = \"D:\\\\recsys\\\\datasets\\\\MovieLens\\\\ml-100k\\\\ml-100k\\\\u.data\"\n",
    "output = \"D:\\\\recsys\\\\datasets\\\\MovieLens\\\\ml-100k\\\\ml-100k.csv\"\n",
    "output_positive_only = \"D:\\\\recsys\\\\datasets\\\\MovieLens\\\\ml-100k\\\\ml-100k-gte.csv\"\n",
    "\n",
    "users = []\n",
    "items = []\n",
    "ratings = []\n",
    "timestamps = []\n",
    "\n",
    "print('Reading file {}'.format(path))\n",
    "with open(path, 'r') as f:\n",
    "    for index, line in enumerate(f):\n",
    "        line = line.replace(\"\\n\", \"\")\n",
    "        if line == \"\":\n",
    "            continue\n",
    "        user, item, rating, timestamp = line.split(\"\\t\")\n",
    "        users.append(int(user))\n",
    "        items.append(int(item))\n",
    "        ratings.append(int(rating))\n",
    "        timestamps.append(int(timestamp))\n",
    "    df = pd.DataFrame({\"User\": users, \"Item\": items, \"Rating\": ratings, \"Timestamp\": timestamps})\n",
    "    \n",
    "print('Sorting by timestamp')\n",
    "df = df.sort_values(by=[\"Timestamp\"])\n",
    "\n",
    "print('Optimizing indexes')\n",
    "df = optimize(df)\n",
    "\n",
    "print('Writing csv file')\n",
    "with open(output, 'w+') as f:\n",
    "    with open(output_positive_only, \"w+\") as f_positive:\n",
    "        for index, row in df.iterrows():\n",
    "            f.write(\"{},{},{},{}\\n\".format(row['User'], row['Item'], row['Rating'], row['Timestamp']))\n",
    "            if row['Rating'] == 5:\n",
    "                f_positive.write(\"{},{},1,{}\\n\".format(row['User'], row['Item'], row['Timestamp']))\n",
    "print(\"Complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Palco Principal - Music-listen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file D:\\recsys\\datasets\\palco\\listenedtracks1.tsv\n",
      "Reading file D:\\recsys\\datasets\\palco\\listenedtracks2.tsv\n",
      "Sorting by timestamp\n",
      "Grouping users and items ... OK\n",
      "Adding to a dictionary ... OK\n",
      "Writing csv file\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "k_value = 2\n",
    "path = \"D:\\\\recsys\\\\datasets\\\\palco\\\\\"\n",
    "music_listen = \"{}music_listen.csv\".format(path, k_value)\n",
    "\n",
    "\n",
    "users = []\n",
    "items = []\n",
    "timestamps = []\n",
    "\n",
    "\n",
    "for file in ['listenedtracks1.tsv', 'listenedtracks2.tsv']:\n",
    "    print('Reading file {}'.format(path + file))\n",
    "    with open(\"{}{}\".format(path, file), 'r') as f:\n",
    "        next(f)\n",
    "        for index, line in enumerate(f):\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            if line == \"\":\n",
    "                continue\n",
    "            user, item, dt = line.split(\"\\t\")\n",
    "            \n",
    "            user = int(user)\n",
    "            users.append(user)\n",
    "            items.append(int(item))\n",
    "\n",
    "            dt = datetime.strptime(dt, \"%Y-%m-%d %H:%M:%S\")\n",
    "            timestamps.append(int(datetime.timestamp(dt)))\n",
    "            \n",
    "df = pd.DataFrame({\"User\": users, \"Item\": items, \"Timestamp\": timestamps})\n",
    "    \n",
    "print('Sorting by timestamp')\n",
    "df = df.sort_values(by=[\"Timestamp\"])\n",
    "\n",
    "print(\"Grouping users and items ... \", end=\"\")\n",
    "items = df.groupby(\"Item\").count().index.values\n",
    "users = df.groupby(\"User\").count().index.values\n",
    "item_dict = {}\n",
    "user_dict = {}\n",
    "print(\"OK\")\n",
    "\n",
    "    \n",
    "print(\"Adding to a dictionary ... \" , end=\"\")\n",
    "for index, item in enumerate(items):\n",
    "    item_dict[item] = index\n",
    "\n",
    "for index, user in enumerate(users):\n",
    "    user_dict[user] = index\n",
    "print(\"OK\")        \n",
    "\n",
    "del users\n",
    "del items\n",
    "del timestamps\n",
    "\n",
    "# print('K{}-Sampling'.format(k_value))\n",
    "# df = k_sampling(df,k_value)\n",
    "\n",
    "print('Writing csv file')\n",
    "with open(music_listen, 'w+') as f:\n",
    "    for index, row in df.iterrows():\n",
    "        f.write(\"{},{},1,{}\\n\".format(user_dict[row['User']], item_dict[row['Item']], row['Timestamp']))\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = df.groupby(\"Item\").count().index.values\n",
    "users = df.groupby(\"User\").count().index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73031"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Palco Principal - Music-playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "path = \"D:\\\\recsys\\\\datasets\\\\palco\\\\\"\n",
    "music_playlist = \"{}music_playlist.csv\".format(path)\n",
    "\n",
    "users = []\n",
    "items = []\n",
    "timestamps = []\n",
    "\n",
    "\n",
    "\n",
    "print('Reading file {}'.format(path + \"playlistedtracks.tsv\"))\n",
    "with open(path + \"playlistedtracks.tsv\", 'r') as f:\n",
    "    next(f)\n",
    "    for index, line in enumerate(f):\n",
    "        line = line.replace(\"\\n\", \"\")\n",
    "        if line == \"\":\n",
    "            continue\n",
    "        user, item, dt = line.split(\"\\t\")\n",
    "        users.append(int(user))\n",
    "        items.append(int(item))\n",
    "        dt = dt.split(\" \")\n",
    "        dt = dt[0].split(\"-\") + dt[1].split(\":\")[:2]\n",
    "        dt = list(map(int, dt))\n",
    "        dt = datetime(dt[0], dt[1], dt[2], dt[3], dt[4])\n",
    "        ts = datetime.timestamp(dt)\n",
    "        timestamps.append(int(ts))\n",
    "df = pd.DataFrame({\"User\": users, \"Item\": items, \"Timestamp\": timestamps})\n",
    "    \n",
    "print('Sorting by timestamp')\n",
    "df = df.sort_values(by=[\"Timestamp\"])\n",
    "\n",
    "print('Optimizing indexes')\n",
    "df = optimize(df)\n",
    "\n",
    "\n",
    "# print('Writing csv file')\n",
    "# with open(music_playlist, 'w+') as f:\n",
    "#     for index, row in df.iterrows():\n",
    "#         f.write(\"{},{},{},{}\\n\".format(row['User'], row['Item'], 1, row['Timestamp']))\n",
    "# print(\"Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Netflix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing csv files ... \n",
      "Index: 100480507 Completed: 99.98%\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from time import time \n",
    "\n",
    "path = \"D:\\\\recsys\\\\datasets\\\\netflix\\\\\"\n",
    "output = \"D:\\\\recsys\\\\datasets\\\\netflix\\\\netflix.csv\"\n",
    "output_positive = \"D:\\\\recsys\\\\datasets\\\\netflix\\\\netflix-gte.csv\"\n",
    "\n",
    "users = []\n",
    "items = []\n",
    "ratings = []\n",
    "timestamps = []\n",
    "counter = 0\n",
    "k_values = [20, 15, 10]\n",
    "print_timer = time()\n",
    "for file in ['combined_data_1.txt', 'combined_data_2.txt', 'combined_data_3.txt', 'combined_data_4.txt']:\n",
    "    header = 'Reading file {}'.format(path + file)\n",
    "    with open(\"{}{}\".format(path, file), 'r') as f:\n",
    "        for index, line in enumerate(f):\n",
    "            counter += 1\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            if line == \"\":\n",
    "                continue\n",
    "            if line[-1] == \":\":\n",
    "                user = int(line.replace(':',''))\n",
    "                continue\n",
    "            item, rating, date = line.split(',')\n",
    "            if time() - print_timer > 2:\n",
    "                print_timer = time()\n",
    "                clear_output()\n",
    "                print(header)\n",
    "                print(\"Index: {} Completed: {:.2f}%\".format(counter, (counter + 1)/100498277 * 100))\n",
    "            item = int(item)\n",
    "            rating = int(rating)\n",
    "            users.append(user)\n",
    "            items.append(item)\n",
    "            ratings.append(rating)\n",
    "            timestamp = int(datetime.timestamp(datetime.strptime(date, \"%Y-%m-%d\")))\n",
    "            timestamps.append(timestamp)\n",
    "\n",
    "df = pd.DataFrame({\"User\": users, \"Item\": items, \"Rating\" : ratings, \"Timestamp\": timestamps})\n",
    "\n",
    "\n",
    "clear_output()\n",
    "print(\"Index: {} Completed: {:.2f}%\".format(counter, (counter + 1)/100498277 * 100))\n",
    "print('Sorting by timestamp')\n",
    "df = df.sort_values(by=[\"Timestamp\"])\n",
    "\n",
    "print(\"Grouping items ... \", end=\"\")\n",
    "items = df.groupby(\"Item\").count().index.values\n",
    "item_dict = {}\n",
    "print(\"OK\")\n",
    "        \n",
    "print(\"Adding to a dictionary ... \" , end=\"\")\n",
    "for index, item in enumerate(items):\n",
    "    item_dict[item] = index\n",
    "print(\"OK\")        \n",
    "\n",
    "del users\n",
    "del items\n",
    "del timestamps\n",
    "del ratings\n",
    "\n",
    "print_timer = time()\n",
    "counter = 0\n",
    "print(\"Writing csv files ... \", end=\"\")\n",
    "with open(output, 'w+') as out:\n",
    "    with open(output_positive, \"w+\") as f_positive:\n",
    "        for index, row in df.iterrows():\n",
    "            counter += 1\n",
    "            if time() - print_timer > 2:\n",
    "                print_timer = time()\n",
    "                clear_output()\n",
    "                print(\"Writing csv files ... \")\n",
    "                print(\"Index: {} Completed: {:.2f}%\".format(counter, (counter + 1)/100498277 * 100))\n",
    "\n",
    "            item = item_dict[row[\"Item\"]]\n",
    "            out.write(\"{},{},{},{}\\n\".format(row[\"User\"], item, row[\"Rating\"], row[\"Timestamp\"]))\n",
    "            if row[\"Rating\"] == 5:\n",
    "                f_positive.write(\"{},{},1,{}\\n\".format(row[\"User\"], item, row[\"Timestamp\"]))\n",
    "clear_output()\n",
    "print(\"Writing csv files ... \")\n",
    "print(\"Index: {} Completed: {:.2f}%\".format(counter, (counter + 1)/100498277 * 100))\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# items = df.groupby(\"Item\").count().index.values\n",
    "users = df.groupby(\"User\").count().index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Item\"].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LastFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "from time import time\n",
    "\n",
    "path = \"D:\\\\recsys\\\\datasets\\\\LastFM\\\\lastfm-dataset-360K\\\\lastfm-dataset-1K\\\\userid-timestamp-artid-artname-traid-traname.tsv\"\n",
    "output = \"D:\\\\recsys\\\\datasets\\\\LastFM\\\\lastfm-dataset-360K\\\\lastfm-dataset-1K\\\\last-fm.csv\"\n",
    "\n",
    "hash_it = lambda x : hashlib.sha224(x.encode('utf-8')).hexdigest()\n",
    "\n",
    "users = []\n",
    "items = []\n",
    "timestamps = []\n",
    "\n",
    "print('Reading file {}'.format(path))\n",
    "with open(path, 'r', encoding=\"utf8\") as f:\n",
    "    print_timer = time()\n",
    "    refused = 0\n",
    "    for index, line in enumerate(f):\n",
    "        line = line.replace(\"\\n\", \"\")\n",
    "        if line == \"\":\n",
    "            continue\n",
    "        user, timestamp, _, artist, _, music = line.split(\"\\t\")\n",
    "        if time() - print_timer > 2:\n",
    "            print_timer = time()\n",
    "            clear_output()\n",
    "            print(\"Index: {} Completed: {:.2f}% Users: {} Items: {}\".format(index, (index + 1)/19150868 * 100, len(all_users), len(all_items)))\n",
    "            print_controller = 0\n",
    "        item = (artist, music)\n",
    "        users.append(int(user[-4:]))\n",
    "        items.append(hash_it(str(item)))\n",
    "        dt = datetime.strptime(timestamp, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "        timestamps.append(int(datetime.timestamp(dt)))\n",
    "    df = pd.DataFrame({\"User\": users, \"Item\": items, \"Timestamp\": timestamps})\n",
    "        \n",
    "clear_output()\n",
    "print(\"Index: {} Completed: {:.2f}% Users: {} Items: {}\".format(index, (index + 1)/19150868 * 100, len(all_users), len(all_items)))\n",
    "print('Sorting by timestamp')\n",
    "df = df.sort_values(by=[\"Timestamp\"])\n",
    "\n",
    "items = df.groupby(\"Item\").count().index.values\n",
    "item_dict = {}\n",
    "    \n",
    "for index, item in enumerate(items):\n",
    "    item_dict[item] = index\n",
    "\n",
    "del df\n",
    "del users\n",
    "del timestamp\n",
    "\n",
    "with open(path, 'r', encoding=\"utf8\") as f:\n",
    "    with open(output, 'w+') as out:\n",
    "        print_timer = time()\n",
    "        refused = 0\n",
    "        for index, line in enumerate(f):\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            if line == \"\":\n",
    "                continue\n",
    "            user, timestamp, _, artist, _, music = line.split(\"\\t\")\n",
    "            if time() - print_timer > 2:\n",
    "                print_timer = time()\n",
    "                clear_output()\n",
    "                print(\"Index: {} Completed: {:.2f}% Users: {} Items: {}\".format(index, (index + 1)/19150868 * 100, len(all_users), len(all_items)))\n",
    "                print_controller = 0\n",
    "            item = (artist, music)\n",
    "            dt = datetime.strptime(timestamp, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "            out.write(\"{},{},1,{}\\n\".format(int(user[-4:]), item_dict[hash_it(str(item))], int(datetime.timestamp(dt))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output\n",
    "from time import time\n",
    "\n",
    "path = \"D:\\\\recsys\\\\datasets\\\\LastFM\\\\lastfm-dataset-360K\\\\lastfm-dataset-1K\\\\last-fm-preprocessed.csv\"\n",
    "out = \"D:\\\\recsys\\\\datasets\\\\LastFM\\\\lastfm-dataset-360K\\\\lastfm-dataset-1K\\\\last-fm.csv\"\n",
    "\n",
    "hash_it = lambda x : hashlib.sha224(x.encode('utf-8')).hexdigest()\n",
    "\n",
    "users = []\n",
    "items = []\n",
    "timestamps = []\n",
    "\n",
    "print('Reading file {}'.format(path))\n",
    "with open(path, 'r', encoding=\"utf8\") as f:\n",
    "    print_timer = time()\n",
    "    refused = 0\n",
    "    for index, line in enumerate(f):\n",
    "        line = line.replace(\"\\n\", \"\")\n",
    "        if line == \"\":\n",
    "            continue\n",
    "        user, item, _, timestamp = line.split(\",\")\n",
    "        if time() - print_timer > 2:\n",
    "            print_timer = time()\n",
    "            clear_output()\n",
    "            print(\"Index: {} Completed: {:.2f}% Users: {} Items: {}\".format(index, (index + 1)/19150868 * 100, len(all_users), len(all_items)))\n",
    "            print_controller = 0\n",
    "        items.append(item)\n",
    "        users.append(user)\n",
    "        timestamps.append(timestamp)\n",
    "    df = pd.DataFrame({\"User\": users, \"Item\": items, \"Timestamp\": timestamps})\n",
    "        \n",
    "clear_output()\n",
    "print(\"Index: {} Completed: {:.2f}% Users: {} Items: {}\".format(index, (index + 1)/19150868 * 100, len(all_users), len(all_items)))\n",
    "print('Sorting by timestamp')\n",
    "df = df.sort_values(by=[\"Timestamp\"])\n",
    "\n",
    "print(\"Writing csv files\")\n",
    "with open(output, 'w+') as f:\n",
    "    for index, row in df.iterrows():\n",
    "        f.write(\"{},{},1,{}\\n\".format(row['User'], row['Item'], row['Timestamp']))\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "out = \"D:\\\\recsys\\\\datasets\\\\LastFM\\\\lastfm-dataset-360K\\\\lastfm-dataset-1K\\\\last-fm-K{}.csv\"\n",
    "\n",
    "k_values = np.arange(2,15)\n",
    "\n",
    "for k in k_values:\n",
    "    with open(out.format(k), 'w+') as f:\n",
    "        print(\"K{}-Sampling.. \".format(k), end=\"\")\n",
    "        sampled = k_sampling(df, k)\n",
    "        print(\"OK\")        \n",
    "        print(\"Writing file.. \", end=\"\")\n",
    "        for index, row in sampled.iterrows():\n",
    "            f.write(\"{},{},1,{}\\n\".format(row['User'], row['Item'], row['Timestamp']))\n",
    "        print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CiaoDVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "\n",
    "path = \"D:\\\\recsys\\\\datasets\\\\CiaoDVD\\\\movie-ratings.txt\"\n",
    "output = \"D:\\\\recsys\\\\datasets\\\\CiaoDVD\\\\ciaodvd.csv\"\n",
    "output_positive = \"D:\\\\recsys\\\\datasets\\\\CiaoDVD\\\\ciaodvd-gte.csv\"\n",
    "\n",
    "\n",
    "users = []\n",
    "items = []\n",
    "ratings = []\n",
    "timestamps = []\n",
    "\n",
    "# file = []\n",
    "\n",
    "print('Reading file {}'.format(path))\n",
    "with open(path, 'r', encoding=\"utf8\") as f:\n",
    "    for index, line in enumerate(f):\n",
    "        line = line.replace(\"\\n\", \"\")\n",
    "        if line == \"\":\n",
    "            continue\n",
    "        user, item, _, _, rating, timestamp = line.split(\",\")\n",
    "        users.append(int(user))\n",
    "        items.append(int(item))\n",
    "        ratings.append(int(rating))\n",
    "        dt = datetime.strptime(timestamp, \"%Y-%m-%d\")\n",
    "        timestamps.append(int(datetime.timestamp(dt)))\n",
    "    df = pd.DataFrame({\"User\": users, \"Item\": items, \"Rating\": ratings, \"Timestamp\": timestamps})\n",
    "        \n",
    "print('Sorting by timestamp')\n",
    "df = df.sort_values(by=[\"Timestamp\"])\n",
    "\n",
    "print('Optimizing indexes')\n",
    "df = optimize(df)\n",
    "\n",
    "\n",
    "print(\"Writing csv files\")\n",
    "with open(output, 'w+') as f:\n",
    "    with open(output_positive, \"w+\") as f_positive:\n",
    "        for index, row in df.iterrows():\n",
    "            f.write(\"{},{},{},{}\\n\".format(row['User'], row['Item'], row['Rating'], row['Timestamp']))\n",
    "            if row['Rating'] == 5:\n",
    "                f_positive.write(\"{},{},1,{}\\n\".format(row['User'], row['Item'], row['Timestamp']))\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EachMovie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "\n",
    "\n",
    "\n",
    "path = \"D:\\\\recsys\\\\datasets\\\\EachMovie\\\\Vote.txt\"\n",
    "output = \"D:\\\\recsys\\\\datasets\\\\EachMovie\\\\eachmovie-K{}.csv\"\n",
    "output_positive = \"D:\\\\recsys\\\\datasets\\\\EachMovie\\\\eachmovie-K{}-gte.csv\"\n",
    "\n",
    "def zero_padding(datetime):\n",
    "    date, time = datetime.split(\" \")\n",
    "    zdate = map('{0:02d}'.format, map(int, date.split(\"/\")))\n",
    "    ztime = map('{0:02d}'.format, map(int, time.split(\":\")))\n",
    "    return \"{} {}\".format(\"/\".join(zdate), \":\".join(ztime)) \n",
    "\n",
    "\n",
    "users = []\n",
    "items = []\n",
    "ratings = []\n",
    "timestamps = []\n",
    "k_value = 5\n",
    "# file = []\n",
    "\n",
    "print('Reading file {}'.format(path))\n",
    "with open(path, 'r', encoding=\"utf8\") as f:\n",
    "    for index, line in enumerate(f):\n",
    "        line = line.replace(\"\\n\", \"\")\n",
    "        if line == \"\":\n",
    "            continue\n",
    "        user, item, rating, _, timestamp = line.split(\"\\t\")\n",
    "        users.append(int(user))\n",
    "        items.append(int(item))\n",
    "        ratings.append(int(float(rating)*5))\n",
    "        dt = datetime.strptime(zero_padding(timestamp), \"%m/%d/%y %H:%M:%S\")\n",
    "        timestamps.append(int(datetime.timestamp(dt)))\n",
    "    df = pd.DataFrame({\"User\": users, \"Item\": items, \"Rating\": ratings, \"Timestamp\": timestamps})\n",
    "        \n",
    "print('Sorting by timestamp')\n",
    "df = df.sort_values(by=[\"Timestamp\"])\n",
    "\n",
    "print('Optimizing indexes')\n",
    "df = k_sampling(df, k_value)\n",
    "\n",
    "\n",
    "print(\"Writing csv files\")\n",
    "with open(output.format(k_value), 'w+') as f:\n",
    "    with open(output_positive.format(k_value), \"w+\") as f_positive:\n",
    "        for index, row in df.iterrows():\n",
    "            f.write(\"{},{},{},{}\\n\".format(row['User'], row['Item'], row['Rating'], row['Timestamp']))\n",
    "            if row['Rating'] == 5:\n",
    "                f_positive.write(\"{},{},1,{}\\n\".format(row['User'], row['Item'], row['Timestamp']))\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieTweetings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "paths = [\"D:\\\\recsys\\\\datasets\\\\MovieTweetings\\\\test.dat\", \"D:\\\\recsys\\\\datasets\\\\MovieTweetings\\\\training.dat\", \"D:\\\\recsys\\\\datasets\\\\MovieTweetings\\\\evaluation.dat\"]\n",
    "\n",
    "output = \"D:\\\\recsys\\\\datasets\\\\MovieTweetings\\\\movietweetings.csv\"\n",
    "output_positive = \"D:\\\\recsys\\\\datasets\\\\MovieTweetings\\\\movietweetings-gte.csv\"\n",
    "\n",
    "users = []\n",
    "items = []\n",
    "ratings = []\n",
    "timestamps = []\n",
    "\n",
    "def process_base(path):\n",
    "    print('Reading file {}'.format(path))\n",
    "    with open(path, 'r', encoding=\"utf8\") as f:\n",
    "        for index, line in enumerate(f):\n",
    "            if index == 0:\n",
    "                continue\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            if line == \"\":\n",
    "                continue\n",
    "            line = line.split(\"{\")[0].split(\",\")\n",
    "            user, item, rating, timestamp, _ = line\n",
    "            if int(rating) > 10:\n",
    "                continue\n",
    "            users.append(int(user))\n",
    "            items.append(int(item))\n",
    "            ratings.append(int(rating))\n",
    "            timestamps.append(int(timestamp))\n",
    "\n",
    "for path in paths:\n",
    "    process_base(path)\n",
    "\n",
    "df = pd.DataFrame({\"User\": users, \"Item\": items, \"Rating\": ratings, \"Timestamp\": timestamps})\n",
    "        \n",
    "print('Sorting by timestamp')\n",
    "df = df.sort_values(by=[\"Timestamp\"])\n",
    "\n",
    "print('Optimizing indexes')\n",
    "df = optimize(df)\n",
    "\n",
    "print(\"Writing csv files\")\n",
    "with open(output, 'w+') as f:\n",
    "    with open(output_positive, \"w+\") as f_positive:\n",
    "        for index, row in df.iterrows():\n",
    "            f.write(\"{},{},{},{}\\n\".format(row['User'], row['Item'], row['Rating'], row['Timestamp']))\n",
    "            if row['Rating'] == 5:\n",
    "                f_positive.write(\"{},{},1,{}\\n\".format(row['User'], row['Item'], row['Timestamp']))\n",
    "print(\"Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YELP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "from IPython.display import clear_output\n",
    "import json\n",
    "\n",
    "\n",
    "path = \"D:\\\\recsys\\\\datasets\\\\YELP\\\\yelp_dataset\\\\yelp_academic_dataset_review.json\"\n",
    "\n",
    "output = \"D:\\\\recsys\\\\datasets\\\\YELP\\\\yelp_dataset\\\\yelp.csv\"\n",
    "output_positive = \"D:\\\\recsys\\\\datasets\\\\YELP\\\\yelp_dataset\\\\yelp-gte.csv\"\n",
    "\n",
    "k_values = [5, 2]\n",
    "\n",
    "users = []\n",
    "items = []\n",
    "ratings = []\n",
    "timestamps = []\n",
    "\n",
    "print_timer = time()\n",
    "\n",
    "print('Reading file {}'.format(path))\n",
    "with open(path, 'r', encoding=\"utf8\") as f:\n",
    "    for index, line in enumerate(f):\n",
    "        line = line.replace(\"\\n\", \"\")\n",
    "        if line == \"\":\n",
    "            continue\n",
    "        data = json.loads(line.split(',\"text\"')[0] + \"}\")\n",
    "        user, item, rating, date = data[\"user_id\"], data[\"business_id\"], data[\"stars\"], data[\"date\"]\n",
    "        users.append(str(user))\n",
    "        items.append(str(item))\n",
    "        ratings.append(int(rating))\n",
    "        dt = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "        timestamps.append(int(datetime.timestamp(dt)))\n",
    "        if time() - print_timer > 2:\n",
    "            print_timer = time()\n",
    "            clear_output()\n",
    "            print(\"Index: {} Completed: {:.2f}%\".format(index, (index + 1)/5996997 * 100))\n",
    "            print_controller = 0\n",
    "clear_output()\n",
    "print(\"Index: {} Completed: {:.2f}%\".format(index, (index + 1)/5996997 * 100))\n",
    "\n",
    "df = pd.DataFrame({\"User\": users, \"Item\": items, \"Rating\": ratings, \"Timestamp\": timestamps})\n",
    "        \n",
    "print('Sorting by timestamp')\n",
    "df = df.sort_values(by=[\"Timestamp\"])\n",
    "\n",
    "print(\"Grouping users and items ... \", end=\"\")\n",
    "items = df.groupby(\"Item\").count().index.values\n",
    "users = df.groupby(\"User\").count().index.values\n",
    "item_dict = {}\n",
    "user_dict = {}\n",
    "print(\"OK\")\n",
    "\n",
    "    \n",
    "print(\"Adding to a dictionary ... \" , end=\"\")\n",
    "for index, item in enumerate(items):\n",
    "    item_dict[item] = index\n",
    "\n",
    "for index, user in enumerate(users):\n",
    "    user_dict[user] = index\n",
    "print(\"OK\")        \n",
    "\n",
    "del df\n",
    "del users\n",
    "del items\n",
    "del timestamps\n",
    "\n",
    "print(\"Writing csv files ... \", end=\"\")\n",
    "with open(path, 'r', encoding=\"utf8\") as f:\n",
    "    with open(output, 'w+') as out:\n",
    "        with open(output_positive, \"w+\") as f_positive:\n",
    "            for index, line in enumerate(f):\n",
    "                if time() - print_timer > 2:\n",
    "                    print_timer = time()\n",
    "                    clear_output()\n",
    "                    print(\"Writing csv files ... \")\n",
    "                    print(\"Index: {} Completed: {:.2f}%\".format(index, (index + 1)/5996997 * 100))\n",
    "                line = line.replace(\"\\n\", \"\")\n",
    "                data = json.loads(line.split(',\"text\"')[0] + \"}\")\n",
    "                user, item, rating, date = user_dict[data[\"user_id\"]], item_dict[data[\"business_id\"]], data[\"stars\"], data[\"date\"]\n",
    "                timestamp = int(datetime.timestamp(datetime.strptime(date, \"%Y-%m-%d\")))\n",
    "                out.write(\"{},{},{},{}\\n\".format(user, item, rating, timestamp))\n",
    "                if rating == 5:\n",
    "                    f_positive.write(\"{},{},1,{}\\n\".format(user, item, timestamp))\n",
    "clear_output()\n",
    "print(\"Writing csv files ... \")\n",
    "print(\"Index: {} Completed: {:.2f}%\".format(index, (index + 1)/5996997 * 100))\n",
    "print(\"Completed\")\n",
    "# for k in k_values:\n",
    "#     print('K{}-Sampling'.format(k))\n",
    "#     st = k_sampling(df, k)\n",
    "#     print(\"Compression rate: {:.2f}% Ratings: {}\".format(100 - st.shape[0]/df.shape[0]*100, st.shape[0]))\n",
    "\n",
    "#     print(\"Writing K{} csv files\".format(k))\n",
    "#     with open(output.format(k), 'w+') as f:\n",
    "#         with open(output_positive.format(k), \"w+\") as f_positive:\n",
    "#             for index, row in st.iterrows():\n",
    "#                 f.write(\"{},{},{},{}\\n\".format(row['User'], row['Item'], row['Rating'], row['Timestamp']))\n",
    "#                 if row['Rating'] == 5:\n",
    "#                     f_positive.write(\"{},{},1,{}\\n\".format(row['User'], row['Item'], row['Timestamp']))\n",
    "# print(\"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = k_sampling(df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
